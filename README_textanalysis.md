# テキスト分析アプリケーション 📊

Word、Excel、CSVファイルなどから文章データを読み込み、日本語テキストの形態素解析、センチメント分析、Wordcloud生成、共起ネットワーク解析を実施するWebアプリケーションです。

## 機能 ✨

### 1. ファイル読み込み
- **対応形式**: Word (.docx), Excel (.xlsx), CSV (.csv), テキスト (.txt)
- 複数の列やページからテキストを自動抽出

### 2. 形態素解析
- Janomeを使用した日本語形態素解析
- 品詞フィルタリング（名詞、動詞、形容詞、副詞）
- ストップワードの自動除去

### 3. 基本統計
- 総文字数
- 総単語数
- ユニーク単語数
- 語彙の豊かさ（TTR: Type-Token Ratio）
- 頻出単語ランキング

### 4. センチメント分析
- ポジティブ/ネガティブ/ニュートラルな単語の自動識別
- センチメントスコアの計算（-1 〜 +1）
- 感情分布の可視化（円グラフ）
- 感情を持つ単語の詳細表示

### 5. Wordcloud生成
- 頻出単語を視覚的に表示
- 日本語フォント対応
- 最大表示単語数の調整可能

### 6. 共起ネットワーク分析
- 単語間の共起関係を分析
- インタラクティブなネットワークグラフ表示
- 共起ウィンドウサイズの調整
- 最小出現回数のフィルタリング
- トップN共起ペアの表示

## インストール 🚀

### 必要なパッケージ

```bash
pip install -r requirements_textanalysis.txt
```

主要なパッケージ:
- `streamlit`: Webアプリケーションフレームワーク
- `janome`: 日本語形態素解析
- `wordcloud`: Wordcloud生成
- `matplotlib`, `seaborn`: データ可視化
- `networkx`: ネットワーク分析
- `plotly`: インタラクティブグラフ
- `pandas`, `numpy`: データ処理
- `openpyxl`: Excelファイル読み込み
- `python-docx`: Wordファイル読み込み

## 使い方 📖

### アプリケーションの起動

```bash
streamlit run text_analysis_app.py
```

ブラウザが自動的に開き、アプリケーションが表示されます（デフォルト: http://localhost:8501）。

### 基本的な使い方

1. **ファイルのアップロード**
   - サイドバーの「ファイルをアップロード」からファイルを選択
   - 対応形式: .docx, .xlsx, .csv, .txt

2. **分析の実行**
   - サイドバーの「🔍 分析を実行」ボタンをクリック
   - 自動的に全ての分析が実施されます

3. **結果の確認**
   - 基本統計: 文字数、単語数、語彙の豊かさ
   - 頻出単語: トップ20の単語と出現回数
   - センチメント分析: ポジティブ/ネガティブの分布
   - Wordcloud: 視覚的な単語の表示
   - 共起ネットワーク: 単語間の関係性

### パラメータ調整

サイドバーから以下のパラメータを調整できます：

- **Wordcloud**
  - 最大表示単語数 (50-200)

- **共起ネットワーク**
  - 共起ウィンドウサイズ (2-10): 共起を検出する範囲
  - 最小出現回数 (1-10): 表示する単語の最小出現回数
  - 表示する共起ペア数 (10-50): ネットワークグラフに表示するペア数

### サンプルテキストで試す

ファイルをアップロードせずに、画面下部の「サンプルテキストで試す」セクションで、
任意のテキストを入力して分析を試すことができます。

## 出力例 📊

### 基本統計
```
総文字数: 1,234
総単語数: 567
ユニーク単語数: 234
語彙の豊かさ: 41.27%
```

### センチメント分析
```
ポジティブ単語: 23
ネガティブ単語: 12
センチメントスコア: 0.314
```

### 共起ネットワーク
インタラクティブなグラフで、単語間の共起関係を可視化します。
- ノードのサイズ: 単語の出現回数
- エッジの太さ: 共起回数
- マウスオーバーで詳細情報を表示

## 技術詳細 🔧

### 形態素解析
- **エンジン**: Janome
- **フィルタ**: 名詞、動詞、形容詞、副詞
- **前処理**: ストップワード除去、1文字単語除外

### センチメント分析
- **方式**: 辞書ベース
- **辞書**: 日本語のポジティブ/ネガティブ単語リスト（約60語）
- **スコア計算**: (ポジティブ数 - ネガティブ数) / 総単語数

### 共起ネットワーク
- **アルゴリズム**: スライディングウィンドウ方式
- **レイアウト**: Spring Layout（NetworkX）
- **可視化**: Plotly（インタラクティブ）

## ファイル構成 📁

```
.
├── text_analysis_app.py          # メインアプリケーション
├── requirements_textanalysis.txt # 必要なパッケージリスト
└── README_textanalysis.md        # このファイル
```

## カスタマイズ 🎨

### センチメント辞書の拡張

`TextAnalyzer` クラスの `__init__` メソッド内で、
`self.positive_words` と `self.negative_words` に単語を追加できます：

```python
self.positive_words = set([
    '良い', 'すばらしい', '素晴らしい', '最高',
    # 追加の単語...
])
```

### ストップワードの調整

`self.stop_words` に追加・削除することで、
分析から除外する単語を調整できます。

### 品詞フィルタの変更

`tokenize` メソッドの `pos_filter` パラメータを変更することで、
抽出する品詞を調整できます。

## トラブルシューティング 🔧

### フォントエラー
日本語が正しく表示されない場合、システムに日本語フォントをインストールしてください：

```bash
# Ubuntu/Debian
sudo apt-get install fonts-ipafont-gothic fonts-ipafont-mincho

# macOS
# 標準でインストールされています
```

### メモリエラー
大きなファイルを処理する場合、メモリ不足になる可能性があります。
その場合は、ファイルを分割するか、分析パラメータを調整してください。

## 今後の改善予定 🚧

- [ ] 他の形態素解析エンジンのサポート（MeCab等）
- [ ] センチメント辞書の改善・拡張
- [ ] トピックモデリング（LDA）の追加
- [ ] 結果のエクスポート機能（PDF、Excel等）
- [ ] バッチ処理機能（複数ファイルの一括分析）
- [ ] カスタム辞書のアップロード機能

## ライセンス 📄

MIT License

## 作成者 👤

AI Code Assistant

---

**Enjoy Text Analysis! 📊✨**
